# ğŸ“š DocumentaciÃ³n TÃ©cnica

## Arquitectura del Proyecto

### ğŸ—ï¸ Stack TecnolÃ³gico

- **Frontend**: Streamlit
- **Backend**: Python 3.9+
- **IA/LLM**: AWS Bedrock (Claude Sonnet 4.5)
- **Web Scraping**: BeautifulSoup4, Requests
- **Geocoding**: Geopy (Nominatim)
- **Mapas**: Folium
- **ValidaciÃ³n**: Pydantic

### ğŸ“‚ Estructura de Carpetas

```
supermercado-comparador/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/              # Modelos de datos (Pydantic)
â”‚   â”‚   â””â”€â”€ models.py        # Producto, Supermercado, etc.
â”‚   â”œâ”€â”€ scrapers/            # Web scrapers
â”‚   â”‚   â”œâ”€â”€ base_scraper.py  # Clase base abstracta
â”‚   â”‚   â”œâ”€â”€ atomo_scraper.py # Scraper de Atomo (real)
â”‚   â”‚   â””â”€â”€ mock_scrapers.py # Scrapers simulados
â”‚   â”œâ”€â”€ services/            # Servicios
â”‚   â”‚   â”œâ”€â”€ bedrock_service.py    # AWS Bedrock
â”‚   â”‚   â””â”€â”€ geocoding_service.py  # GeocodificaciÃ³n
â”‚   â”œâ”€â”€ utils/               # Utilidades
â”‚   â””â”€â”€ app.py              # AplicaciÃ³n Streamlit
â”œâ”€â”€ data/
â”‚   â””â”€â”€ supermercados_data.py # BD de supermercados
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py            # ConfiguraciÃ³n global
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_basic.py        # Tests bÃ¡sicos
â””â”€â”€ requirements.txt         # Dependencias
```

## ğŸ”„ Flujo de Trabajo

### 1. Usuario ingresa consulta

```
Input: "cumpleaÃ±os para 50 personas" + "GuaymallÃ©n, Mendoza"
```

### 2. Bedrock interpreta la consulta

```python
{
  "productos": ["gaseosas", "panchos", "hamburguesas", ...],
  "evento": "cumpleaÃ±os",
  "personas": 50
}
```

### 3. GeocodificaciÃ³n

```python
ubicacion = geocoding.obtener_coordenadas("GuaymallÃ©n, Mendoza")
# -> Ubicacion(lat=-32.8895, lon=-68.8458)
```

### 4. Filtrado de supermercados

```python
supermercados_cercanos = geocoding.filtrar_por_distancia(
    ubicacion, 
    todos_supermercados,
    max_distancia_km=10
)
```

### 5. Web Scraping

```python
for supermercado in supermercados_cercanos:
    scraper = scrapers[supermercado.nombre]
    productos = scraper.buscar_multiples_productos(productos_lista)
```

### 6. ComparaciÃ³n y ranking

```python
comparaciones.sort(key=lambda x: x.calcular_score())
# Score = (0.7 * precio) + (0.3 * distancia * 1000)
```

### 7. RecomendaciÃ³n con IA

```python
recomendacion = bedrock.generar_recomendacion(
    comparaciones,
    ubicacion
)
```

### 8. VisualizaciÃ³n en Streamlit

- Tabla comparativa
- MÃ©tricas
- Mapa interactivo
- Detalles de productos

## ğŸ§© Componentes Clave

### BedrockService

InteractÃºa con AWS Bedrock para:
- Interpretar consultas en lenguaje natural
- Extraer productos y eventos
- Generar recomendaciones inteligentes
- Validar dominio de consultas

**MÃ©todos principales:**
```python
def interpretar_consulta(mensaje: str) -> Dict
def generar_recomendacion(comparaciones: List, ubicacion: str) -> str
def _validar_dominio(mensaje: str) -> bool
```

### GeocodingService

Maneja geolocalizaciÃ³n y distancias:
- Convierte direcciones en coordenadas
- Calcula distancias entre puntos
- Filtra por radio
- Estima tiempos de viaje

**MÃ©todos principales:**
```python
def obtener_coordenadas(direccion: str) -> Ubicacion
def calcular_distancia(origen, destino) -> float
def filtrar_por_distancia(ubicacion, supermercados, max_km) -> List
```

### BaseScraper (Abstracto)

Clase base para todos los scrapers con:
- Manejo de sesiones HTTP
- Headers rotativos
- Rate limiting
- Error handling

**MÃ©todos abstractos:**
```python
def buscar_producto(nombre: str) -> List[Producto]
def obtener_url_busqueda(query: str) -> str
```

### Scrapers EspecÃ­ficos

#### AtomoScraper (Real)
- Scraping de atomoconviene.com
- Mapeo de categorÃ­as
- Parsing de HTML real

#### Mock Scrapers (Simulados)
- Precios realistas generados algorÃ­tmicamente
- VariaciÃ³n por supermercado (factores de precio)
- Ãštiles para demo y testing

## ğŸ” Seguridad y Buenas PrÃ¡cticas

### Variables de Entorno
```bash
# .env
AWS_ACCESS_KEY_ID=xxx
AWS_SECRET_ACCESS_KEY=xxx
AWS_REGION=us-east-1
```

### Rate Limiting
- Delay de 2 segundos entre requests
- User-agent rotativo
- Session pooling

### ValidaciÃ³n de Datos
- Modelos Pydantic para type safety
- ValidaciÃ³n de dominio en consultas
- SanitizaciÃ³n de inputs

## ğŸ§ª Testing

### Tests BÃ¡sicos
```bash
python tests/test_basic.py
```

Incluye:
- Test de scrapers
- Test de geocoding
- Test de datos
- Test de flujo completo

### Tests Unitarios (TODO)
```bash
pytest tests/
```

## ğŸš€ Despliegue

### OpciÃ³n 1: Streamlit Cloud
1. Push a GitHub
2. Conectar con Streamlit Cloud
3. Configurar secrets (AWS credentials)

### OpciÃ³n 2: Docker
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8501
CMD ["streamlit", "run", "src/app.py"]
```

### OpciÃ³n 3: Servidor Local
```bash
streamlit run src/app.py --server.port 8501
```

## ğŸ“Š Performance

### Optimizaciones
- Caching de geocodificaciÃ³n
- ParalelizaciÃ³n de scrapers (TODO)
- Cache de precios (TTL 1 hora)

### Tiempos Esperados
- GeocodificaciÃ³n: ~1s
- Scraping por supermercado: 2-5s
- Total (5 supermercados): 10-25s

## ğŸ”® Mejoras Futuras

1. **Scrapers Reales**
   - Implementar scrapers para todos los supermercados
   - Usar Selenium para sitios dinÃ¡micos

2. **Base de Datos**
   - PostgreSQL para histÃ³rico de precios
   - Redis para caching

3. **ParalelizaciÃ³n**
   - Asyncio para scrapers concurrentes
   - Reduce tiempo total de bÃºsqueda

4. **Notificaciones**
   - Alertas de precio
   - Ofertas especiales

5. **MÃ³vil**
   - PWA con Streamlit
   - App nativa (Flutter/React Native)

6. **ML/Analytics**
   - PredicciÃ³n de precios
   - AnÃ¡lisis de tendencias
   - Recomendaciones personalizadas

## ğŸ› Troubleshooting

### Error: "No module named 'boto3'"
```bash
pip install -r requirements.txt
```

### Error: "Bedrock credentials not found"
```bash
# Verificar .env
cat .env
# Debe tener AWS_ACCESS_KEY_ID y AWS_SECRET_ACCESS_KEY
```

### Error: "Can't connect to atomoconviene.com"
- Verificar conexiÃ³n a internet
- El sitio puede estar bloqueando scrapers
- Usar mock scrapers para testing

### Streamlit no se ejecuta
```bash
# Verificar instalaciÃ³n
streamlit --version

# Reinstalar si es necesario
pip install streamlit --upgrade
```

## ğŸ“ Soporte

Para bugs o sugerencias:
- GitHub Issues: [repo]/issues
- Email: tu@email.com

## ğŸ“„ Licencia

MIT License - Ver LICENSE file
